---
title: "Less is More: Techniques to Reduce Overfitting in your Transformer Model for Sign Language Recognition"
collection: publications
permalink: /publication/2023-06-18-lessIsMore-overfitting
excerpt: 'Sign language recognition (SLR) in deep learning is a challenging task due to the need for interpreting human body movements, including detailed hand movements and facial expressions. Recent research has focused on using keypoint body landmarks and transformer models to improve SLR performance. However, these models can face overfitting issues due to the need for more available datasets. To address these problems, we analyze three Peruvian sign language (LSP) datasets for SLR. Additionally, we apply several techniques to reduce overfitting in the Spoter model, a transformer-based architecture for SLR. The results of these techniques reveal that the data-based techniques improve generalization and reduce overfitting in transformer-based models for SLR.'
date: 2023-06-18
venue: 'Computer Vision and Pattern Recognition Conference: LatinX in AI (LXAI) Research Workshop 2023'
paperurl: 'https://research.latinxinai.org/papers/cvpr/2023/pdf/Joe_Huamani.pdf'
citation: 'Huamani Malca, J. N. et al., (2023). Less is More: Techniques to Reduce Overfitting in your Transformer Model for Sign Language Recognition [Poster Presentation]. Computer Vision and Pattern Recognition Conference: LatinX in AI (LXAI) Research Workshop 2023, Vancouver, Canada.'
---

<a href='https://research.latinxinai.org/papers/cvpr/2023/pdf/Joe_Huamani.pdf'>Download paper here</a>

Sign language recognition (SLR) in deep learning is a challenging task due to the need for interpreting human body movements, including detailed hand movements and facial expressions. Recent research has focused on using keypoint body landmarks and transformer models to improve SLR performance. However, these models can face overfitting issues due to the need for more available datasets. To address these problems, we analyze three Peruvian sign language (LSP) datasets for SLR. Additionally, we apply several techniques to reduce overfitting in the Spoter model, a transformer-based architecture for SLR. The results of these techniques reveal that the data-based techniques improve generalization and reduce overfitting in transformer-based models for SLR.

Recommended citation: Huamani Malca, J. N. et al., (2023). Less is More: Techniques to Reduce Overfitting in your Transformer Model for Sign Language Recognition [Poster Presentation]. Computer Vision and Pattern Recognition Conference: LatinX in AI (LXAI) Research Workshop 2023, Vancouver, Canada.